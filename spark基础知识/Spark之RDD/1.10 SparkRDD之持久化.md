# 持久性存储级别（Spark Persistence Storage Levels）

所有不同的持久性（persist() 方法）存储级别 Spark/PySpark 支持分别在 org.apache.spark.storage.StorageLevel 和 pyspark.StorageLevel 类中可用。 

在使用Spark/PySpark RDD、DataFrame 和 Dataset时，可以指定存储级别以及持久化或缓存 。

>  All different persistence (persist() method) storage level Spark/PySpark supports are available at `org.apache.spark.storage.StorageLevel` and `pyspark.StorageLevel` classes respectively. The storage level specifies how and where to persist or cache a Spark/PySpark RDD, DataFrame, and Dataset.

所有这些存储级别都作为参数传递给 Spark/Pyspark RDD、DataFrame 和 Dataset 的 persist() 方法。

> All these Storage levels are passed as an argument to the persist() method of the Spark/Pyspark RDD, DataFrame, and Dataset.



**For example**

```scala
import org.apache.spark.storage.StorageLevel
val rdd2 = rdd.persist(StorageLevel.MEMORY_ONLY_SER)
or 
val df2 = df.persist(StorageLevel.MEMORY_ONLY_SER)

```

## RDD存储级别

### 仅内存存储级别(Memory only Storage level)

`StorageLevel.MEMORY_ONLY` 是 **RDD 的默认行为**方法并将 RDD 或 DataFrame 作为反序列化对象存储到 JVM 内存中。 <font color=red>当没有足够的可用内存时，它不会保存某些分区的 DataFrame，并且这些将在需要时重新计算。</font>

> `StorageLevel.MEMORY_ONLY` is the default behavior of the RDD  method and stores the RDD or DataFrame as deserialized objects to JVM memory. When there is not enough memory available it will not save DataFrame of some partitions and these will be re-computed as and when required.

这需要更多的内存。 但与 RDD 不同的是，这比 **MEMORY_AND_DISK** 级别慢，<font color=red>因为它重新计算未保存的分区，并且重新计算底层表的内存中列表示是昂贵的</font>。

> This takes more memory. but unlike RDD, this would be slower than **MEMORY_AND_DISK** level as it recomputes the unsaved partitions, and recomputing the in-memory columnar representation of the underlying table is expensive.



### 序列化内存级别(Serialize in Memory)

`StorageLevel.MEMORY_ONLY_SER` 与 `MEMORY_ONLY` 相同，<font color=red>但不同之处在于它将 RDD 作为序列化对象存储到 JVM 内存中。 它比 MEMORY_ONLY 占用更少的内存（节省空间），因为它将对象保存为序列化，但这个需要时，需要额外的几个 CPU 周期才能进行反序列化</font>。

> `StorageLevel.MEMORY_ONLY_SER` is the same as `MEMORY_ONLY` but the difference being it stores RDD as serialized objects to JVM memory. It takes lesser memory (space-efficient) than MEMORY_ONLY as it saves objects as serialized and takes an additional few more CPU cycles in order to deserialize.



### 仅内存存储级别-复制（Memory only and Replicate）

`StorageLevel.MEMORY_ONLY_2` 与 `MEMORY_ONLY` 存储级别相同，但将每个分区复制到两个集群节点。

> `StorageLevel.MEMORY_ONLY_2` is same as `MEMORY_ONLY` storage level but replicate each partition to two cluster nodes.

### 序列化内存级别-复制（Serialized in Memory and Replicate）

`StorageLevel.MEMORY_ONLY_SER_2` 与 `MEMORY_ONLY_SER` 存储级别相同，但将每个分区复制到两个集群节点。

> `StorageLevel.MEMORY_ONLY_SER_2` is same as `MEMORY_ONLY_SER` storage level but replicate each partition to two cluster nodes.

## DataFrame/Dataset存储级别

### 内存存储/磁盘级别（Memory and Disk Storage level）

`StorageLevel.MEMORY_AND_DISK` 是 **DataFrame 或 Dataset** 的默认行为。 在此存储级别中，DataFrame 将作为反序列化对象存储在 JVM 内存中。 当所需的存储空间大于可用内存时，它会将一些多余的分区存储到磁盘中，并在需要时从磁盘中读取数据。 由于涉及 I/O，因此速度较慢。

> <font color=red>`StorageLevel.MEMORY_AND_DISK` is the default behavior of the DataFrame or Dataset</font>. In this Storage Level, The DataFrame will be stored in JVM memory as deserialized objects. When required storage is greater than available memory, it stores some of the excess partitions into a disk and reads the data from the disk when required. It is slower as there is I/O involved.

### 序列化存储/磁盘级别（Serialize in Memory and Disk）

`StorageLevel.MEMORY_AND_DISK_SER` 与 `MEMORY_AND_DISK` 存储级别差异相同，因为当空间不可用时，它会在内存和磁盘上序列化 DataFrame 对象。

> `StorageLevel.MEMORY_AND_DISK_SER` is same as `MEMORY_AND_DISK` storage level difference being it serializes the DataFrame objects in memory and on disk when space is not available.

### 7 内存存储/磁盘级别-复制（Memory, Disk and Replicate）

`StorageLevel.MEMORY_AND_DISK_2` 与`MEMORY_AND_DISK` 存储级别相同，但将每个分区复制到两个集群节点。

> `StorageLevel.MEMORY_AND_DISK_2` is Same as `MEMORY_AND_DISK` storage level but replicate each partition to two cluster nodes.

### 序列化存储/磁盘级别-复制（Serialize in Memory, Disk and Replicate）

`StorageLevel.MEMORY_AND_DISK_SER_2` 与 `MEMORY_AND_DISK_SER` 存储级别相同，但将每个分区复制到两个集群节点。

> `StorageLevel.MEMORY_AND_DISK_SER_2` is same as `MEMORY_AND_DISK_SER` storage level but replicate each partition to two cluster nodes.



## 磁盘存储级别（Disk only storage level）

在 `StorageLevel.DISK_ONLY` 存储级别中，DataFrame 仅存储在磁盘上，<font color=red>由于涉及 I/O，CPU 计算时间很高。</font>

> In `StorageLevel.DISK_ONLY` storage level, DataFrame is stored only on disk and the CPU computation time is high as I/O involved.

## 磁盘存储级别（Disk only and Replicate）

`StorageLevel.DISK_ONLY_2` 与 `DISK_ONLY` 存储级别相同，但将每个分区复制到两个集群节点。

> `StorageLevel.DISK_ONLY_2` is same as `DISK_ONLY` storage level but replicate each partition to two cluster nodes.

## 如何使用

下面是存储级别的表格表示，通过空间、CPU 和性能的影响选择最适合您的一个。

> Below is the table representation of the Storage level, Go through the impact of space, CPU, and performance choose the one that best fits you.

```scala

Storage Level    Space used  CPU time  In memory  On-disk  Serialized   Recompute some partitions
----------------------------------------------------------------------------------------------------
MEMORY_ONLY          High        Low       Y          N        N         Y    
MEMORY_ONLY_SER      Low         High      Y          N        Y         Y
MEMORY_AND_DISK      High        Medium    Some       Some     Some      N
MEMORY_AND_DISK_SER  Low         High      Some       Some     Y         N
DISK_ONLY            Low         High      N          Y        Y         N

```

## Reference

- https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence

# 总结

可以从是否序列化和存储在哪个位置来，来区分和记忆spark提供的存储级别。



