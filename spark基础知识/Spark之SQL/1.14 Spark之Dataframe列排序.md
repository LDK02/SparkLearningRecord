# Spark 之Dataframe列排序

在 Spark 中，您可以使用 DataFrame/Dataset 的 `sort()` 或 `orderBy()` 函数对单列或多列进行升序或降序排序，也可以使用 Spark SQL 排序函数]进行排序]，在本文中，我将使用 Scala 示例解释所有这些不同的方式。

> In Spark, you can use either `sort()` or `orderBy()` function of DataFrame/Dataset to sort by ascending or descending order based on single or multiple columns, you can also do sorting using [Spark SQL sorting functions](https://sparkbyexamples.com/spark/spark-sql-sort-functions/), In this article, I will explain all these different ways using Scala examples.

## 目录

- [1 使用 sort() 函数对 DataFrame 进行排序](#1 使用 sort() 函数对 DataFrame 进行排序)
- [2 使用 orderBy() 函数对 DataFrame 进行排序](#2 使用 orderBy() 函数对 DataFrame 进行排序)
- [3 按升序排序 (ASC)](#3 按升序排序 (ASC))
- [4 降序排序 (DESC)](#4 降序排序 (DESC))
- [5 使用排序函数](#5 使用排序函数)
- [6 在 SQL 上使用排序](#6 在 SQL 上使用排序)
- [7 Dataframe 排序完整示例](#7 Dataframe 排序完整示例)

在开始之前，首先让我们创建一个 DataFrame。

```scala
  import spark.implicits._

  val simpleData = Seq(("James","Sales","NY",90000,34,10000),
    ("Michael","Sales","NY",86000,56,20000),
    ("Robert","Sales","CA",81000,30,23000),
    ("Maria","Finance","CA",90000,24,23000),
    ("Raman","Finance","CA",99000,40,24000),
    ("Scott","Finance","NY",83000,36,19000),
    ("Jen","Finance","NY",79000,53,15000),
    ("Jeff","Marketing","CA",80000,25,18000),
    ("Kumar","Marketing","NY",91000,50,21000)
  )
  val df = simpleData.toDF("employee_name","department","state","salary","age","bonus")
  df.show()
```

This Yields below output.

```scala
root
 |-- employee_name: string (nullable = true)
 |-- department: string (nullable = true)
 |-- state: string (nullable = true)
 |-- salary: integer (nullable = false)
 |-- age: integer (nullable = false)
 |-- bonus: integer (nullable = false)

+-------------+----------+-----+------+---+-----+
|employee_name|department|state|salary|age|bonus|
+-------------+----------+-----+------+---+-----+
|        James|     Sales|   NY| 90000| 34|10000|
|      Michael|     Sales|   NY| 86000| 56|20000|
|       Robert|     Sales|   CA| 81000| 30|23000|
|        Maria|   Finance|   CA| 90000| 24|23000|
|        Raman|   Finance|   CA| 99000| 40|24000|
|        Scott|   Finance|   NY| 83000| 36|19000|
|          Jen|   Finance|   NY| 79000| 53|15000|
|         Jeff| Marketing|   CA| 80000| 25|18000|
|        Kumar| Marketing|   NY| 91000| 50|21000|
+-------------+----------+-----+------+---+-----+
```

## 1 使用 sort() 函数对 DataFrame 进行排序

Spark DataFrame/Dataset 类提供 `sort()` 函数来对一列或多列进行排序。 默认情况下，它按升序排序。

> Spark DataFrame/Dataset class provides `sort()` function to sort on one or more columns. By default, it sorts by ascending order.

**Syntax**

```scala
sort(sortCol : scala.Predef.String, sortCols : scala.Predef.String*) : Dataset[T]
sort(sortExprs : org.apache.spark.sql.Column*) : Dataset[T]
```

**Example**

```scala
df.sort("department","state").show(false)
df.sort(col("department"),col("state")).show(false)
```

上面的两个示例返回相同的输出，第一个将 DataFrame 列名称作为字符串，下一个将列采用 Column 类型。 该表按第一个“部门”列排序，然后是“状态”列。

> The above two examples return the same below output, the first one takes the DataFrame column name as a string and the next takes columns in Column type. This table sorted by the first `department` column and then the `state` column.

```scala
+-------------+----------+-----+------+---+-----+
|employee_name|department|state|salary|age|bonus|
+-------------+----------+-----+------+---+-----+
|Maria        |Finance   |CA   |90000 |24 |23000|
|Raman        |Finance   |CA   |99000 |40 |24000|
|Jen          |Finance   |NY   |79000 |53 |15000|
|Scott        |Finance   |NY   |83000 |36 |19000|
|Jeff         |Marketing |CA   |80000 |25 |18000|
|Kumar        |Marketing |NY   |91000 |50 |21000|
|Robert       |Sales     |CA   |81000 |30 |23000|
|James        |Sales     |NY   |90000 |34 |10000|
|Michael      |Sales     |NY   |86000 |56 |20000|
+-------------+----------+-----+------+---+-----+
```

## 2 使用 orderBy() 函数对 DataFrame 进行排序

或者，Spark DataFrame/Dataset 类还提供了 `orderBy()` 函数来对一个或多个列进行排序。 默认情况下，它也按升序排序。

> Alternatively, Spark DataFrame/Dataset class also provides `orderBy()` function to sort on one or more columns. By default, it also orders by ascending.

**Syntax**

```scala
orderBy(sortCol : scala.Predef.String, sortCols : scala.Predef.String*) : Dataset[T]
orderBy(sortExprs : org.apache.spark.sql.Column*) : Dataset[T]
```

**Example**

```scala
df.orderBy("department","state").show(false)
df.orderBy(col("department"),col("state")).show(false)
```



## 3 按升序排序 (ASC)

如果要在 DataFrame 上明确指定升序/排序，可以使用 `sort`和`orderBy`函数的方法。 例如

```scala
df.sort(col("department").asc,col("state").asc).show(false)
df.orderBy(col("department").asc,col("state").asc).show(false)
```

The above two examples return the same output.

```scala
+-------------+----------+-----+------+---+-----+
|employee_name|department|state|salary|age|bonus|
+-------------+----------+-----+------+---+-----+
|Maria        |Finance   |CA   |90000 |24 |23000|
|Raman        |Finance   |CA   |99000 |40 |24000|
|Jen          |Finance   |NY   |79000 |53 |15000|
|Scott        |Finance   |NY   |83000 |36 |19000|
|Jeff         |Marketing |CA   |80000 |25 |18000|
|Kumar        |Marketing |NY   |91000 |50 |21000|
|Robert       |Sales     |CA   |81000 |30 |23000|
|James        |Sales     |NY   |90000 |34 |10000|
|Michael      |Sales     |NY   |86000 |56 |20000|
+-------------+----------+-----+------+---+-----+
```

## 4 降序排序 (DESC)

如果要在 DataFrame 上明确指定降序/排序，可以使用 `sort`和`orderBy`函数的方法。 例如

```scala
df.sort(col("department").asc,col("state").desc).show(false)
df.orderBy(col("department").asc,col("state").desc).show(false)
```

This yields the below output.

```scala
+-------------+----------+-----+------+---+-----+
|employee_name|department|state|salary|age|bonus|
+-------------+----------+-----+------+---+-----+
|Scott        |Finance   |NY   |83000 |36 |19000|
|Jen          |Finance   |NY   |79000 |53 |15000|
|Raman        |Finance   |CA   |99000 |40 |24000|
|Maria        |Finance   |CA   |90000 |24 |23000|
|Kumar        |Marketing |NY   |91000 |50 |21000|
|Jeff         |Marketing |CA   |80000 |25 |18000|
|James        |Sales     |NY   |90000 |34 |10000|
|Michael      |Sales     |NY   |86000 |56 |20000|
|Robert       |Sales     |CA   |81000 |30 |23000|
+-------------+----------+-----+------+---+-----+
```

## 5 使用排序函数

Spark SQL 函数提供了几个排序函数，下面是一些如何使用 [asc](https://sparkbyexamples.com/spark/spark-sql-sort-functions/#asc) 和 [desc](https:// sparkbyexamples.com/spark/spark-sql-sort-functions/#desc) 函数。 除此之外，Spark 还提供 [asc_nulls_first](https://sparkbyexamples.com/spark/spark-sql-sort-functions/#asc-nulls-first) 和 [asc_nulls_last](https://sparkbyexamples.com/spark/spark -sql-sort-functions/#asc-nulls-last) 函数和降序的等效函数。

> Spark SQL function provides several sorting functions, below are some examples of how to use [asc](https://sparkbyexamples.com/spark/spark-sql-sort-functions/#asc) and [desc](https://sparkbyexamples.com/spark/spark-sql-sort-functions/#desc) functions. Besides these Spark also provides [asc_nulls_first](https://sparkbyexamples.com/spark/spark-sql-sort-functions/#asc-nulls-first) and [asc_nulls_last](https://sparkbyexamples.com/spark/spark-sql-sort-functions/#asc-nulls-last) functions and equivalent for descending.

```scala
df.select($"employee_name",asc("department"),desc("state"),$"salary",$"age",$"bonus").show(false)
```

## 在 SQL 上使用排序

```scala
df.createOrReplaceTempView("EMP")
spark.sql(" select employee_name,asc('department'),desc('state'),salary,age,bonus from EMP").show(false)
```



## Dataframe 排序完整示例

```scala
package com.sparkbyexamples.spark.dataframe.functions

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
object SortExample extends App {

  val spark: SparkSession = SparkSession.builder()
    .master("local[1]")
    .appName("SparkByExamples.com")
    .getOrCreate()

  spark.sparkContext.setLogLevel("ERROR")

  import spark.implicits._

  val simpleData = Seq(("James","Sales","NY",90000,34,10000),
    ("Michael","Sales","NY",86000,56,20000),
    ("Robert","Sales","CA",81000,30,23000),
    ("Maria","Finance","CA",90000,24,23000),
    ("Raman","Finance","CA",99000,40,24000),
    ("Scott","Finance","NY",83000,36,19000),
    ("Jen","Finance","NY",79000,53,15000),
    ("Jeff","Marketing","CA",80000,25,18000),
    ("Kumar","Marketing","NY",91000,50,21000)
  )
  val df = simpleData.toDF("employee_name","department","state","salary","age","bonus")
  df.printSchema()
  df.show()

  df.sort("department","state").show(false)
  df.sort(col("department"),col("state")).show(false)

  df.orderBy("department","state").show(false)
  df.orderBy(col("department"),col("state")).show(false)

  df.sort(col("department").asc,col("state").asc).show(false)
  df.orderBy(col("department").asc,col("state").asc).show(false)

  df.sort(col("department").asc,col("state").desc).show(false)
  df.orderBy(col("department").asc,col("state").desc).show(false)
 df.select($"employee_name",asc("department"),desc("state"),$"salary",$"age",$"bonus").show(false)
  df.createOrReplaceTempView("EMP")
  spark.sql(" select employee_name,asc('department'),desc('state'),salary,age,bonus from EMP").show(false)

}
```



## 8 总结

在这里，您学习了如何使用 sort()、orderBy() 和 SQL 排序函数对 Spark DataFrame 列进行排序，并将此函数与 Spark SQL 以及升序和降序排序顺序一起使用。

> Here you have learned how to Sort Spark DataFrame columns using sort(), orderBy() and using SQL sort functions and used this function with Spark SQL along with Ascending and Descending sorting orders.

