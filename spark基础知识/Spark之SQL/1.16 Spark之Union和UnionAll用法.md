# spark 之union and unionAll

在这篇 Spark 文章中，您将学习如何合并相同模式的两个或多个数据帧，这些数据帧用于将 DataFrame 附加到另一个或组合两个 DataFrame，并通过 Scala 示例解释 union 和 union all 之间的区别。

> In this Spark article, you will learn how to union two or more data frames of the same schema which is used to append DataFrame to another or combine two DataFrames and also explain the differences between union and union all with Scala examples.

Dataframe union() - DataFrame 的`union()` 方法用于组合两个相同结构/模式的 DataFrame。 如果模式不同，则返回错误。

DataFrame unionAll() - `unionAll()` 自 Spark “2.0.0” 版本以来已弃用，并替换为 union()。

> Dataframe union() – `union()` method of the DataFrame is used to combine two DataFrame’s of the same structure/schema. If schemas are not the same it returns an error.
>
> DataFrame unionAll() – `unionAll()` is deprecated since Spark “2.0.0” version and replaced with union().

**注意：** 在其他 SQL 中，Union 消除了重复项，但 UnionAll 组合了两个数据集，包括重复记录。 但是，在 spark 中两者的行为相同并使用 [DataFrame 重复函数删除重复行](https://sparkbyexamples.com/spark/spark-remove-duplicate-rows/)。

> **Note:** In other SQL’s, Union eliminates the duplicates but UnionAll combines two datasets including duplicate records. But, in spark both behave the same and use [DataFrame duplicate function to remove duplicate rows](https://sparkbyexamples.com/spark/spark-remove-duplicate-rows/).

首先，让我们创建两个具有相同架构的 DataFrame。

> First, let’s create two DataFrame with the same schema.

```scala
import spark.implicits._

  val simpleData = Seq(("James","Sales","NY",90000,34,10000),
    ("Michael","Sales","NY",86000,56,20000),
    ("Robert","Sales","CA",81000,30,23000),
    ("Maria","Finance","CA",90000,24,23000)
  )
  val df = simpleData.toDF("employee_name","department","state","salary","age","bonus")
  df.printSchema()
  df.show()
```

This yields the below schema and DataFrame output.

```scala
root
 |-- employee_name: string (nullable = true)
 |-- department: string (nullable = true)
 |-- state: string (nullable = true)
 |-- salary: integer (nullable = false)
 |-- age: integer (nullable = false)
 |-- bonus: integer (nullable = false)

+-------------+----------+-----+------+---+-----+
|employee_name|department|state|salary|age|bonus|
+-------------+----------+-----+------+---+-----+
|        James|     Sales|   NY| 90000| 34|10000|
|      Michael|     Sales|   NY| 86000| 56|20000|
|       Robert|     Sales|   CA| 81000| 30|23000|
|        Maria|   Finance|   CA| 90000| 24|23000|
+-------------+----------+-----+------+---+-----+
```

现在，让我们创建第二个数据，其中包含新记录和来自上述数据框的一些记录，但具有相同的模式。

> Now, let’s create a second Dataframe with the new records and some records from the above Dataframe but with the same schema.



```scala
  val simpleData2 = Seq(("James","Sales","NY",90000,34,10000),
    ("Maria","Finance","CA",90000,24,23000),
    ("Jen","Finance","NY",79000,53,15000),
    ("Jeff","Marketing","CA",80000,25,18000),
    ("Kumar","Marketing","NY",91000,50,21000)
  )
  val df2 = simpleData2.toDF("employee_name","department","state","salary","age","bonus")
```

This yields below output

```scala
+-------------+----------+-----+------+---+-----+
|employee_name|department|state|salary|age|bonus|
+-------------+----------+-----+------+---+-----+
|James        |Sales     |NY   |90000 |34 |10000|
|Maria        |Finance   |CA   |90000 |24 |23000|
|Jen          |Finance   |NY   |79000 |53 |15000|
|Jeff         |Marketing |CA   |80000 |25 |18000|
|Kumar        |Marketing |NY   |91000 |50 |21000|
+-------------+----------+-----+------+---+-----+
```

## 使用 union 组合两个或多个 DataFrame

DataFrame `union()` 方法结合两个 DataFrame 并返回新的 DataFrame 以及来自两个 Dataframe 的所有行，<font color=red>而不管重复数据</font>。

> DataFrame `union()` method combines two DataFrames and returns the new DataFrame with all rows from two Dataframes regardless of duplicate data.

```scala
  val df3 = df.union(df2)
  df3.show(false)
```

As you see below it returns all records.

```scala
+-------------+----------+-----+------+---+-----+
|employee_name|department|state|salary|age|bonus|
+-------------+----------+-----+------+---+-----+
|James        |Sales     |NY   |90000 |34 |10000|
|Michael      |Sales     |NY   |86000 |56 |20000|
|Robert       |Sales     |CA   |81000 |30 |23000|
|Maria        |Finance   |CA   |90000 |24 |23000|
|James        |Sales     |NY   |90000 |34 |10000|
|Maria        |Finance   |CA   |90000 |24 |23000|
|Jen          |Finance   |NY   |79000 |53 |15000|
|Jeff         |Marketing |CA   |80000 |25 |18000|
|Kumar        |Marketing |NY   |91000 |50 |21000|
+-------------+----------+-----+------+---+-----+
```

## 使用 unionAll 组合 DataFrame

DataFrame `unionAll()` 方法自 Spark “2.0.0” 版本以来已弃用，建议使用 union() 方法。

> DataFrame `unionAll()` method is deprecated since Spark “2.0.0” version and recommends using the union() method.

```scala
  val df4 = df.unionAll(df2)
  df4.show(false)
```

## 使用 union 组合两个或多个 DataFrame且去重

由于 union() 方法返回所有没有不同记录的行，因此我们将使用 `distinct()` 函数在存在重复记录时仅返回一条记录。

> Since the union() method returns all rows without distinct records, we will use the `distinct()` function to return just one record when duplicate exists.

```scala
  val df5 = df.union(df2).distinct()
  df5.show(false)
```

Yields below output. As you see, this returns only distinct rows.

```scala
+-------------+----------+-----+------+---+-----+
|employee_name|department|state|salary|age|bonus|
+-------------+----------+-----+------+---+-----+
|James        |Sales     |NY   |90000 |34 |10000|
|Maria        |Finance   |CA   |90000 |24 |23000|
|Jeff         |Marketing |CA   |80000 |25 |18000|
|Jen          |Finance   |NY   |79000 |53 |15000|
|Kumar        |Marketing |NY   |91000 |50 |21000|
|Michael      |Sales     |NY   |86000 |56 |20000|
|Robert       |Sales     |CA   |81000 |30 |23000|
+-------------+----------+-----+------+---+-----+
```

## 完整代码

```scala
package com.sparkbyexamples.spark.dataframe

import org.apache.spark.sql.SparkSession

object UnionExample extends App{

  val spark: SparkSession = SparkSession.builder()
    .master("local[1]")
    .appName("SparkByExamples.com")
    .getOrCreate()

  spark.sparkContext.setLogLevel("ERROR")

  import spark.implicits._

  val simpleData = Seq(("James","Sales","NY",90000,34,10000),
    ("Michael","Sales","NY",86000,56,20000),
    ("Robert","Sales","CA",81000,30,23000),
    ("Maria","Finance","CA",90000,24,23000)
  )
  val df = simpleData.toDF("employee_name","department","state","salary","age","bonus")
  df.printSchema()
  df.show()

  val simpleData2 = Seq(("James","Sales","NY",90000,34,10000),
    ("Maria","Finance","CA",90000,24,23000),
    ("Jen","Finance","NY",79000,53,15000),
    ("Jeff","Marketing","CA",80000,25,18000),
    ("Kumar","Marketing","NY",91000,50,21000)
  )
  val df2 = simpleData2.toDF("employee_name","department","state","salary","age","bonus")
  df2.show(false)

  val df3 = df.union(df2)
  df3.show(false)
  df3.distinct().show(false)

  val df4 = df.unionAll(df2)
  df4.show(false)
}
```



## 总结

在这篇 Spark 文章中，您学习了如何使用 Union 方法将两个或多个相同模式的 DataFrame 组合成单个 DataFrame，并了解 union() 和 unionAll() 函数之间的区别。

> In this Spark article, you have learned how to combine two or more DataFrame’s of the same schema into single DataFrame using Union method and learned the difference between the union() and unionAll() functions.