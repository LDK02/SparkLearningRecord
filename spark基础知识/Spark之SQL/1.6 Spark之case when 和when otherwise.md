# Spark SQL 之case when 和 when otherwise

> Like SQL `"case when"` statement and “`Swith"`, `"if then else"` statement from popular programming languages, Spark SQL Dataframe also supports similar syntax using “`when otherwise`” or we can also use “`case when`” statement. So let’s see an example on how to check for multiple conditions and replicate SQL CASE statement.

与流行编程语言中的 SQL `"case when"` 语句和 "`Swith"`、`"if then else"` 语句一样，Spark SQL Dataframe 也支持使用 "`when else`" 的类似语法，或者我们也可以使用 "` case when`” 语句。让我们看一个关于如何检查多个条件和复制 SQL CASE 语句的示例。

## 目录

[1 准备数据](#1 准备数据)

[2. 在 Spark DataFrame 上使用“**when else**”](#2. 在 Spark DataFrame 上使用“**when else**”)

[3. 在 Spark DataFrame 上使用“**case when**”](#3. 在 Spark DataFrame 上使用“**case when**”)

[4. 使用 && 和 || 操作符](#4. 使用 && 和 || 操作符)

[5 完整代码](#5 完整代码)

[6 总结](#6 总结)

First Let’s do the imports that are needed and [create spark context and DataFrame](https://sparkbyexamples.com/spark/different-ways-to-create-a-spark-dataframe/).

##  准备数据

```scala
import spark.sqlContext.implicits._
val data = List(("James", "", "Smith", "36636", "M", 60000),
                ("Michael", "Rose", "", "40288", "M", 70000),
                ("Robert", "", "Williams", "42114", "", 400000),
                ("Maria", "Anne", "Jones", "39192", "F", 500000),
                ("Jen", "Mary", "Brown", "", "F", 0))
val cols = Seq("first_name","middle_name","last_name","dob","gender","salary")
val df: DataFrame = spark.createDataFrame(data).toDF(cols:_*)
```

## 在 Spark DataFrame 上使用“**when else**”

> `when` is a Spark function, so to use it first we should import using `import org.apache.spark.sql.functions.when` before. Above code snippet replaces the value of gender with new derived value. when value not qualified with the condition, we are assigning “Unknown” as value.

`when` 是一个 Spark 函数，所以要先使用它，我们应该先使用 `import org.apache.spark.sql.functions.when` 导入。 上面的代码片段用新的派生值替换了性别的值。 当值不符合条件时，我们将“未知”分配为值。

```scala
/**
      * 1 当gender为M为时，修改为"Male",为"F"时修改为"Famale",并将原始列名gender修改为new_gender
      * */
val df2: DataFrame = df.withColumn("new_gender", when(col("gender") === "M", "Male")
                                   .when(col("gender") === "F", "Famale")
                                   .otherwise("Unknown"))
df2.show()
```

> `when` can also be used on Spark SQL select statement.

`when` 也可以用于 Spark SQL 的 select 语句。

```scala
 /**
      * 2当gender为M为时，修改为"Male",为"F"时修改为"Famale",并将原始列名gender修改为new_gender
      * */
    val df4: DataFrame = df.select(col("*"), when(col("gender") === "M", "Male")
      .when(col("gender") === "F", "Female")
      .otherwise("Unknown").alias("new_gender"))
    df4.show()

```

## 在 Spark DataFrame 上使用“**case when**”

> Similar to SQL syntax, we could use “case when” with expression `expr()` .

与 SQL 语法类似，我们可以在表达式 `expr()` 中使用“case when”。

```scala
/**
      * 3当gender为M为时，修改为"Male",为"F"时修改为"Famale",并将原始列名gender修改为new_gender
      * */
    val df3: DataFrame = df.withColumn("new_gender",
      expr("case when gender = 'M' then 'Male' " +
        "when gender = 'F' then 'Female' " +
        "else 'Unknown' end"))
    df3.show()
```

> Using within SQL select.

在 SQL 选择中使用。

```scala
/**
      * 4 当gender为M为时，修改为"Male",为"F"时修改为"Famale",并将原始列名gender修改为new_gender
      * */
    val df6: DataFrame = df.select(col("*"),
      expr("case when gender = 'M' then 'Male'" +
        "when gender = 'F' then 'Female' " +
        "else 'Unknown' end ").alias("new_gender"))
    df6.show()
```

##  使用 && 和 || 操作符

> We can also use and (&&) or (||) within when function. To explain this I will use a new set of data to make it simple.

我们还可以在 when 函数中使用 and (&&) 或 (||)。 为了解释这一点，我将使用一组新数据使其变得简单。

```scala
/**
      * 5 当code列的数据，为"a"或"b",则置为啊"A",
      * 当code列的数据为:"b"且为"4"时，则为"B "
      * */
    val dataDF: DataFrame = Seq((66,"a","4"),(67,"a","0"),(70,"b","4"),(71,"d","4")).toDF("id","code","amt")
    println("--------原始数据----------------")
    dataDF.show()

    val dataDF1: DataFrame = dataDF.withColumn("new_column",
      when(col("code") === "a" || col("code") === "d", "A")
        .when(col("code") === "b" && col("amt") === "4", "B")
        .otherwise("A1"))
    println("修改后的数据：")
    dataDF1.show()
```

Output:

```scala
--------原始数据----------------
+---+----+---+
| id|code|amt|
+---+----+---+
| 66|   a|  4|
| 67|   a|  0|
| 70|   b|  4|
| 71|   d|  4|
+---+----+---+

修改后的数据：
+---+----+---+----------+
| id|code|amt|new_column|
+---+----+---+----------+
| 66|   a|  4|         A|
| 67|   a|  0|         A|
| 70|   b|  4|         B|
| 71|   d|  4|         A|
+---+----+---+----------+
```



## 完整代码

```scala
package sparkScalaExamples.SQL

import org.apache.spark.sql.{DataFrame, SparkSession}

object CaseWhenAndOtherDemo {
  def main(args: Array[String]): Unit = {
    val spark: SparkSession =
      SparkSession
        .builder()
        .appName("casewhen")
        .master("local")
        .getOrCreate()

    import spark.sqlContext.implicits._
    val data = List(("James", "", "Smith", "36636", "M", 60000),
      ("Michael", "Rose", "", "40288", "M", 70000),
      ("Robert", "", "Williams", "42114", "", 400000),
      ("Maria", "Anne", "Jones", "39192", "F", 500000),
      ("Jen", "Mary", "Brown", "", "F", 0))
    val cols = Seq("first_name","middle_name","last_name","dob","gender","salary")

    val df: DataFrame = spark.createDataFrame(data).toDF(cols:_*)
    import org.apache.spark.sql.functions._
    /**
      * 1 当gender为M为时，修改为"Male",为"F"时修改为"Famale",并将原始列名gender修改为new_gender
      * */
    val df2: DataFrame = df.withColumn("new_gender", when(col("gender") === "M", "Male")
      .when(col("gender") === "F", "Famale")
      .otherwise("Unknown"))
    df2.show()

    /**
      * 2当gender为M为时，修改为"Male",为"F"时修改为"Famale",并将原始列名gender修改为new_gender
      * */
    val df4: DataFrame = df.select(col("*"), when(col("gender") === "M", "Male")
      .when(col("gender") === "F", "Female")
      .otherwise("Unknown").alias("new_gender"))
    df4.show()

    /**
      * 3当gender为M为时，修改为"Male",为"F"时修改为"Famale",并将原始列名gender修改为new_gender
      * */
    val df3: DataFrame = df.withColumn("new_gender",
      expr("case when gender = 'M' then 'Male' " +
        "when gender = 'F' then 'Female' " +
        "else 'Unknown' end"))
    df3.show()
    /**
      * 4 当gender为M为时，修改为"Male",为"F"时修改为"Famale",并将原始列名gender修改为new_gender
      * */
    val df6: DataFrame = df.select(col("*"),
      expr("case when gender = 'M' then 'Male'" +
        "when gender = 'F' then 'Female' " +
        "else 'Unknown' end ").alias("new_gender"))
    df6.show()
    /**
      * 5 当code列的数据，为"a"或"b",则置为啊"A",
      * 当code列的数据为:"b"且为"4"时，则为"B "
      * */
    val dataDF: DataFrame = Seq((66,"a","4"),(67,"a","0"),(70,"b","4"),(71,"d","4")).toDF("id","code","amt")
    println("--------原始数据----------------")
    dataDF.show()

    val dataDF1: DataFrame = dataDF.withColumn("new_column",
      when(col("code") === "a" || col("code") === "d", "A")
        .when(col("code") === "b" && col("amt") === "4", "B")
        .otherwise("A1"))
    println("修改后的数据：")
    dataDF1.show()




  }

}

```

##  总结

> In this article, we have learned how to use spark “`case when`” using `expr()` function and “`when otherwise`” function on Dataframe also, we’ve learned how to use these functions with && and || logical operators. I hope you like this article.



在本文中，我们学习了如何在 Dataframe 上使用 `expr()` 函数和“`when else`” 函数来使用 spark “`case when`”，我们还学习了如何将这些函数与 && 和 || 一起使用。 逻辑运算符。 我希望你喜欢这篇文章。

