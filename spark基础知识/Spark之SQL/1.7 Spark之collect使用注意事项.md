# Spark 之 collect使用注意事项

> Spark `collect()` and `collectAsList()` are action operation that is used to retrieve all the elements of the RDD/DataFrame/Dataset (from all nodes) to the driver node. We should use the collect() on smaller dataset usually after filter(), group(), count() e.t.c. Retrieving on larger dataset results in out of memory.

Spark `collect()` 和 `collectAsList()` 是用于将 RDD/DataFrame/Dataset 的所有元素（从所有节点）拉到驱动程序节点的操作操作。 我们应该在较小的数据集上使用 collect() 通常在 filter()、group()、count() 等之后。 注意：<font color=red>拉取更大的数据集会导致内存不足</font>。

> In this Spark article, I will explain the usage of `collect()` with DataFrame example, when to avoid it, and the difference between `collect()`and `select()`.

在这篇 Spark 文章中，我将通过 DataFrame 示例解释 `collect()` 的用法，何时避免使用，以及 `collect()` 和 `select()` 之间的区别。

## 准备数据

In order to explain with example, first, let’s [create a DataFrame](https://sparkbyexamples.com/spark/different-ways-to-create-a-spark-dataframe/).

```scala
  val spark:SparkSession = SparkSession.builder()
    .master("local[1]")
    .appName("SparkByExamples.com")
    .getOrCreate()

  val data = Seq(Row(Row("James ","","Smith"),"36636","M",3000),
    Row(Row("Michael ","Rose",""),"40288","M",4000),
    Row(Row("Robert ","","Williams"),"42114","M",4000),
    Row(Row("Maria ","Anne","Jones"),"39192","F",4000),
    Row(Row("Jen","Mary","Brown"),"","F",-1)
  )

  val schema = new StructType()
    .add("name",new StructType()
      .add("firstname",StringType)
      .add("middlename",StringType)
      .add("lastname",StringType))
    .add("id",StringType)
    .add("gender",StringType)
    .add("salary",IntegerType)

  val df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)
  df.printSchema()
  df.show(false)
```

> `show()` function on DataFrame prints the result of the dataset in a table format. By default, it shows only 20 rows. The above snippet returns the data in a table.

DataFrame 上的 `show()` 函数以表格格式打印数据集的结果。 默认情况下，它只显示 20 行。 上面的代码片段返回表格中的数据。

```scala
root
 |-- name: struct (nullable = true)
 |    |-- firstname: string (nullable = true)
 |    |-- middlename: string (nullable = true)
 |    |-- lastname: string (nullable = true)
 |-- id: string (nullable = true)
 |-- gender: string (nullable = true)
 |-- salary: integer (nullable = true)

+---------------------+-----+------+------+
|name                 |id   |gender|salary|
+---------------------+-----+------+------+
|[James , , Smith]    |36636|M     |3000  |
|[Michael , Rose, ]   |40288|M     |4000  |
|[Robert , , Williams]|42114|M     |4000  |
|[Maria , Anne, Jones]|39192|F     |4000  |
|[Jen, Mary, Brown]   |     |F     |-1    |
+---------------------+-----+------+------+
```

## 使用 collect() 和 collectAsList()

`collect()` action function is used to retrieve all elements from the dataset (RDD/DataFrame/Dataset) as a `Array[Row]` to the driver program.

> `collect()` 操作函数用于从数据集 (RDD/DataFrame/Dataset) 中拉取所有元素作为 `Array[Row]` 到驱动程序。

`collectAsList()` 动作函数与 collect() 类似，<font color=red>但它返回 Java util 列表</font>。

> `collectAsList()` action function is similar to collect() but it returns Java util list.

**Syntax:**

```scala
collect() : scala.Array[T]
collectAsList() : java.util.List[T]
```

## collect() 案例

```scala
/**
      *`collect()` 操作函数用于从数据集 (RDD/DataFrame/Dataset) 中拉取所有元素作为 `Array[Row]` 到驱动程序。
      * `collectAsList()` 动作函数与 collect() 类似，但它返回 Java util 列表。
      * */
    val colList: util.List[Row] = df.collectAsList()
    val colData: Array[Row] = df.collect()

    colData.foreach( row => {//row是指每一行,
      val salary: Int = row.getInt(3)//值提取第4列数据
      println(salary)
    })
```

`deptDF.collect()` retrieves all elements in a DataFrame as an array to the driver. From the array, I’ve retried the firstName element and printed on the console.

> `deptDF.collect()` 将 DataFrame 中的所有元素作为数组检索到驱动程序。 从数组中，我重试了 firstName 元素并打印在控制台上。

```scala
3000
4000
4000
4000
-1
```

## 从嵌套结构列中检索数据

> To retrieve a struct column from `Row`, we should use `getStruct()` function.

要从 `Row` 检索结构列，我们应该使用 `getStruct()` 函数。

```scala
 colData.foreach( row => {//row是指每一行,
     val salary: Int = row.getInt(3)//值提取第4列数据
     //提取嵌套数据结果
     //将 struct 类型的位置 i 处的值作为 [[Row]] 对象返回。
     val fullName: Row = row.getStruct(0)//
     val firstName: String = fullName.getString(0)
     val middleName: String = fullName.get(1).toString
     val lastname: String = fullName.getAs[String]("lastname")
     println(firstName + "," + middleName + "," + lastname +"," + salary)
 })
```

> Above example explains the use of different Row class functions `get()`, `getString()`, `getAs[String]()`, `getStruct()`.

上面的例子解释了不同 Row 类函数 `get()`、`getString()`、`getAs[String]()`、`getStruct()` 的使用。

```scala
James ,,Smith,3000
Michael ,Rose,,4000
Robert ,,Williams,4000
Maria ,Anne,Jones,4000
Jen,Mary,Brown,-1
```

Note that like other DataFrame functions, `collect()` does not return a Dataframe instead, it returns data in an array to your driver. once the data is collected in an array, you can use scala language for further processing.

>  请注意，与其他 DataFrame 函数一样，`collect()` 不会返回 Dataframe，而是将数组中的数据返回给您的驱动程序。 将数据收集到数组中后，您可以使用 scala 语言进行进一步处理。

In case you want to just return certain elements of a DataFrame, you should call select() first.

> 如果您只想返回 DataFrame 的某些元素，您应该首先调用 select()。

```scala
 /**
      * 只抽取一列数据到驱动程序，（即从分布节点到主节点）
* */
println("-------------------------")
val dataCollect: Array[Row] = df.select("name").collect()
```

## 何时避免使用 Collect()

Usually, collect() is used to retrieve the action output when you have very small result set and calling `collect()` on an RDD/DataFrame with a bigger result set causes out of memory as it returns the entire dataset (from all workers) to the driver hence we should avoid calling collect() on a larger dataset.

> 通常，当您的结果集非常小时，collect() 用于检索操作输出，<font color=red>并且在具有较大结果集的 RDD/DataFrame 上调用 `collect()` 会导致内存不足</font>，因为它返回整个数据集（来自所有工作人员 ) 到驱动程序，因此我们应该避免在更大的数据集上调用 collect()。

## collect () vs select ()

`select()` method on an RDD/DataFrame returns a new DataFrame that holds the columns that are selected whereas collect() returns the entire data set.

> RDD/DataFrame 上的 `select()` 方法返回一个新的 DataFrame，其中包含选择的列，而 collect() 返回整个数据集。

`select()` is a transformation function whereas `collect()` is an action.

> `select()` 是一个转换函数，而 `collect()` 是一个动作。

## Spark collect() 的完整示例

Below is a complete Spark example of using `collect()` and `collectAsList()` on DataFrame, similarly, you can also create a program with RDD.

> 下面是在 DataFrame 上使用 `collect()` 和 `collectAsList()` 的完整 Spark 示例，同样，您也可以使用 RDD 创建程序。

```scala
package sparkScalaExamples.SQL

import java.util

import org.apache.spark.sql.{Row, SparkSession}
import org.apache.spark.sql.types.{IntegerType, StringType, StructType}

object CollectDmeo {
  def main(args: Array[String]): Unit = {
    val spark: SparkSession = SparkSession
      .builder()
      .appName("collectDemo")
      .master("local")
      .getOrCreate()

    val data = Seq(Row(Row("James ","","Smith"),"36636","M",3000),
      Row(Row("Michael ","Rose",""),"40288","M",4000),
      Row(Row("Robert ","","Williams"),"42114","M",4000),
      Row(Row("Maria ","Anne","Jones"),"39192","F",4000),
      Row(Row("Jen","Mary","Brown"),"","F",-1)
    )

    val schema = new StructType()
      .add("name",new StructType()
        .add("firstname",StringType)
        .add("middlename",StringType)
        .add("lastname",StringType))
      .add("id",StringType)
      .add("gender",StringType)
      .add("salary",IntegerType)

    val df = spark.createDataFrame(spark.sparkContext.parallelize(data),schema)
    println("------------原始数据：-----------------")
    df.printSchema()
    df.show(false)
    /*runcate 是否截断长字符串。 如果为真，超过 20 个字符的字符串将被截断，所有单元格将右对齐*/
    /**
      *`collect()` 操作函数用于从数据集 (RDD/DataFrame/Dataset) 中拉取所有元素作为 `Array[Row]` 到驱动程序。
      * `collectAsList()` 动作函数与 collect() 类似，但它返回 Java util 列表。
      * */
    val colList: util.List[Row] = df.collectAsList()
    val colData: Array[Row] = df.collect()

    colData.foreach( row => {//row是指每一行,
      val salary: Int = row.getInt(3)//值提取第4列数据
      println(salary)
    })

    colData.foreach( row => {//row是指每一行,
      val salary: Int = row.getInt(3)//值提取第4列数据
      //提取嵌套数据结果
      //将 struct 类型的位置 i 处的值作为 [[Row]] 对象返回。
      val fullName: Row = row.getStruct(0)//
      val firstName: String = fullName.getString(0)
      val middleName: String = fullName.get(1).toString
      val lastname: String = fullName.getAs[String]("lastname")
      println(firstName + "," + middleName + "," + lastname +"," + salary)
    })
    /**
      * 只抽取一列数据到驱动程序，（即从分布节点到主节点）
      * */
     println("-------------------------")
     val dataCollect: Array[Row] = df.select("name").collect()




  }

}

```

This example is also available at [Spark Github](https://github.com/spark-examples/spark-scala-examples/blob/master/src/main/scala/com/sparkbyexamples/spark/dataframe/examples/CollectExample.scala) project.

## 5总结Conclusion

> In this Spark article, you have learned the collect() and collectAsList() function of the RDD/DataFrame which returns all elements of the DataFrame to Driver program and also learned it’s not a good practice to use it on the bigger dataset, finally retrieved the data from Struct field.



在这篇 Spark 文章中，您学习了 RDD/DataFrame 的 collect() 和 collectAsList() 函数，它们将 DataFrame 的所有元素返回给 Driver 程序，还了解到在更大的数据集上使用它不是一个好习惯，最后检索到 来自 Struct 字段的数据。

